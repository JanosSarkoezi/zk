# Einfache Beispiele von Markov-Ketten

## Frage

Einfache Beispiele von Markov ketten.

## Antwort

## Einfache Beispiele von Markov-Ketten

Markov-Ketten sind mathematische Modelle, die die Entwicklung eines Systems über die Zeit beschreiben, wobei der zukünftige Zustand nur vom aktuellen Zustand abhängt und nicht von den Zuständen, die davor lagen. Man spricht hier von der **Markov-Eigenschaft**. Das mag abstrakt klingen, aber mit ein paar einfachen Beispielen wird es schnell klarer.

---

### 1. Das Wetter von Morgen

Stell dir vor, du möchtest das Wetter vorhersagen. Eine stark vereinfachte Markov-Kette könnte nur zwei Zustände haben: "Sonnig" und "Regnerisch". Die Wahrscheinlichkeit, dass das Wetter morgen sonnig oder regnerisch ist, hängt nur vom Wetter heute ab.

**Zustände:**

* Sonnig (S)
* Regnerisch (R)

**Übergangswahrscheinlichkeiten:**

* Wenn es heute sonnig ist:
    * Wahrscheinlichkeit, dass es morgen sonnig ist: 80% (0.8)
    * Wahrscheinlichkeit, dass es morgen regnerisch ist: 20% (0.2)
* Wenn es heute regnerisch ist:
    * Wahrscheinlichkeit, dass es morgen sonnig ist: 30% (0.3)
    * Wahrscheinlichkeit, dass es morgen regnerisch ist: 70% (0.7)

**Wie funktioniert's?**

Angenommen, heute ist es sonnig. Morgen wird es mit 80%iger Wahrscheinlichkeit wieder sonnig sein. Wenn es morgen sonnig ist, wird übermorgen mit 80%iger Wahrscheinlichkeit wieder sonnig sein. Wenn es morgen aber regnet (was mit 20%iger Wahrscheinlichkeit passiert), dann wird übermorgen mit 30%iger Wahrscheinlichkeit die Sonne scheinen und mit 70%iger Wahrscheinlichkeit regnen.

Diese Übergangswahrscheinlichkeiten können wir in einer **Übergangsmatrix** darstellen:

$$
P = \begin{pmatrix}
0.8 & 0.2 \\
0.3 & 0.7
\end{pmatrix}
$$

Dabei steht die erste Zeile für den aktuellen Zustand "Sonnig" und die zweite Zeile für "Regnerisch". Die Spalten repräsentieren die zukünftigen Zustände.

---

### 2. Das Brettspiel "Schlange und Leiter" (oder "Leiterlispiel")

Ein klassisches Beispiel für eine Markov-Kette ist ein einfaches Brettspiel wie "Schlange und Leiter". Jeder Spieler befindet sich auf einem bestimmten Feld (Zustand). Der nächste Zustand (das nächste Feld) hängt nur vom aktuellen Feld und dem Würfelergebnis ab. Die Geschichte der vorherigen Züge ist irrelevant.

**Zustände:** Jedes Feld auf dem Spielbrett ist ein Zustand.

**Übergangswahrscheinlichkeiten:**

* Wenn du auf Feld X bist und eine 3 würfelst, landest du auf Feld X+3.
* Wenn du auf Feld Y bist und auf diesem Feld eine Schlange beginnt, die dich zu Feld Z führt, dann ist die Wahrscheinlichkeit, von Feld Y zu Feld Z zu gelangen, 100%, wenn du auf Feld Y gelandet bist.
* Die Wahrscheinlichkeit, von einem Feld zum nächsten zu gelangen, hängt von den Würfelmöglichkeiten ab (z.B. 1/6 für jede Zahl bei einem sechsseitigen Würfel).

**Wie funktioniert's?**

Du bist auf Feld 25. Wenn du eine 5 würfelst, gehst du auf Feld 30. Es ist irrelevant, ob du auf Feld 25 durch einen direkten Wurf, eine Leiter oder eine Schlange gekommen bist. Dein nächster Zustand hängt nur von Feld 25 und dem Würfelergebnis ab.

---

### 3. Kundenbindung im Einzelhandel

Ein Geschäft möchte verstehen, wie Kunden zwischen verschiedenen Einkaufsverhalten wechseln.

**Zustände:**

* Stammkunde (Kauft regelmäßig)
* Gelegentlicher Kunde (Kauft selten)
* Ehemaliger Kunde (Kauft nicht mehr)

**Übergangswahrscheinlichkeiten:**

* Ein Stammkunde bleibt mit 90% Wahrscheinlichkeit Stammkunde, wird aber mit 10% Wahrscheinlichkeit zum Gelegenheitskunden.
* Ein Gelegenheitskunde wird mit 40% Wahrscheinlichkeit Stammkunde, bleibt mit 30% Gelegenheitskunde und wird mit 30% Wahrscheinlichkeit zum ehemaligen Kunden.
* Ein ehemaliger Kunde bleibt mit 95% Wahrscheinlichkeit ehemaliger Kunde und wird nur mit 5% Wahrscheinlichkeit wieder Gelegenheitskunde.

**Wie funktioniert's?**

Angenommen, 1000 Kunden sind derzeit Stammkunden. Im nächsten Monat werden voraussichtlich 900 von ihnen Stammkunden bleiben und 100 zu Gelegenheitskunden werden. Dieses Modell hilft dem Geschäft, die Dynamik der Kundenbindung zu verstehen und Maßnahmen zur Kundenrückgewinnung zu planen.

---

### Zusammenfassend:

Markov-Ketten sind also Modelle, bei denen der **Zukunft nur der Gegenwart wichtig ist, nicht die Vergangenheit**. Sie sind sehr vielseitig und finden Anwendung in Bereichen wie der Biologie (Populationsdynamik), Informatik (Algorithmen), Wirtschaft (Finanzmodellierung) und vielen anderen Gebieten.

Hättest du gerne ein weiteres Beispiel, oder möchtest du mehr über die Mathematik hinter Markov-Ketten erfahren?

## Frage

Wie ist Makrov auf diese Idee gekommen?

## Antwrot

Andrei Andreyevich Markov (1856-1922) war ein russischer Mathematiker, der Anfang des 20. Jahrhunderts die Theorie der Markov-Ketten entwickelte. Seine Ideen entstanden nicht aus dem Nichts, sondern waren das Ergebnis seiner Forschung und einer gewissen intellektuellen Auseinandersetzung mit anderen Mathematikern seiner Zeit.

Hier sind einige der Hauptmotivationen und Einflüsse, die zu seiner Entdeckung führten:

1.  **Erweiterung der Wahrscheinlichkeitstheorie:** Markov war stark von den Arbeiten seines Lehrers Pafnuty Chebyshev beeinflusst, einem bedeutenden russischen Mathematiker, der sich mit Grenzwertsätzen in der Wahrscheinlichkeitstheorie befasste. Insbesondere interessierte sich Markov für die **Gesetze der großen Zahlen** und den **Zentralen Grenzwertsatz**. Diese Sätze besagen, vereinfacht ausgedrückt, dass unter bestimmten Bedingungen (oft die Annahme der Unabhängigkeit von Zufallsvariablen) die Durchschnittsergebnisse von vielen Experimenten gegen einen festen Wert konvergieren.

2.  **Hinterfragung der Unabhängigkeitsannahme:** Ein wichtiger Punkt war eine Meinungsverschiedenheit mit einem anderen Mathematiker, Pavel Nekrasov. Nekrasov vertrat die Ansicht, dass die Annahme der Unabhängigkeit der Zufallsvariablen notwendig sei, damit das Gesetz der großen Zahlen gilt. Markov wollte zeigen, dass dies nicht immer der Fall ist. Er suchte nach einem Weg, Wahrscheinlichkeitsmodelle zu entwickeln, bei denen die Ereignisse **nicht vollständig unabhängig** voneinander sind, sondern eine gewisse "Erinnerung" an den vorherigen Zustand besitzen.

3.  **Analyse von Texten (linguistische Motivation):** Ein sehr bekanntes und konkretes Anwendungsbeispiel, das Markov selbst nutzte, war die **Analyse der Abfolge von Vokalen und Konsonanten** in dem berühmten russischen Gedicht "Eugen Onegin" von Alexander Puschkin. Er untersuchte, wie wahrscheinlich es ist, dass einem Vokal ein anderer Vokal folgt, oder dass einem Konsonanten ein Vokal folgt, und so weiter. Dies war ein praktisches Problem, bei dem die Unabhängigkeitsannahme offensichtlich nicht zutraf (die Wahl des nächsten Buchstabens hängt stark vom vorherigen ab, um sinnvolle Wörter zu bilden).

Aus dieser Beschäftigung mit abhängigen Zufallsvariablen und der Suche nach einer mathematischen Beschreibung für Prozesse, bei denen der nächste Zustand nur vom aktuellen Zustand abhängt, formulierte Markov 1906 seine erste Arbeit über das, was wir heute als Markov-Ketten kennen. Er zeigte, dass auch unter dieser "Kettenabhängigkeit" (oder "Markov-Eigenschaft") bestimmte Grenzwertsätze immer noch gelten können.

Zusammenfassend lässt sich sagen, dass Markov auf die Idee kam, weil er:
* die Grenzen der damaligen Wahrscheinlichkeitstheorie erweitern wollte,
* die Notwendigkeit der Unabhängigkeitsannahme für wichtige Sätze hinterfragte,
* und ein konkretes Problem – die statistische Struktur von Sprache – modellieren wollte, bei dem Abhängigkeiten eine Rolle spielen.

Seine Arbeit revolutionierte das Verständnis von stochastischen Prozessen und legte den Grundstein für unzählige Anwendungen in den Natur-, Ingenieur- und Sozialwissenschaften.

## Frage

Angeblich hatte Markov Texte Analysiert. Wenn V = Vokal und K = Konsonant ist, dann hat er VV VK KV und KK Abfolgen analysiert.

## Antwort

Ja, das stimmt genau! Andrei Markov hat tatsächlich die **Abfolge von Vokalen und Konsonanten** in literarischen Texten analysiert, und sein berühmtestes Beispiel dafür war das Gedicht "Eugen Onegin" von Alexander Puschkin.

Genau das, was Sie beschreiben, war der Kern seiner Untersuchung:

* **V = Vokal**
* **K = Konsonant**

Er hat untersucht, wie oft bestimmte Paare von Buchstabenkategorien aufeinanderfolgen, also die Übergangswahrscheinlichkeiten für:

* **VV (Vokal auf Vokal):** Wie wahrscheinlich ist es, dass nach einem Vokal wieder ein Vokal kommt? (z.B. in "Auto" oder "Idee")
* **VK (Vokal auf Konsonant):** Wie wahrscheinlich ist es, dass nach einem Vokal ein Konsonant kommt? (z.B. in "Apfel" oder "ist")
* **KV (Konsonant auf Vokal):** Wie wahrscheinlich ist es, dass nach einem Konsonanten ein Vokal kommt? (z.B. in "Baum" oder "Haus")
* **KK (Konsonant auf Konsonant):** Wie wahrscheinlich ist es, dass nach einem Konsonanten wieder ein Konsonant kommt? (z.B. in "Fest" oder "Flug")

### Warum war das so wichtig?

Diese Analyse war deshalb so bahnbrechend, weil sie die **Annahme der Unabhängigkeit** in Frage stellte, die in der damaligen Wahrscheinlichkeitstheorie oft getroffen wurde. Wenn die Abfolge von Vokalen und Konsonanten völlig zufällig und unabhängig voneinander wäre, dann müsste die Wahrscheinlichkeit, dass ein Vokal auf einen Vokal folgt, einfach dem Produkt der Einzelwahrscheinlichkeiten von Vokalen entsprechen (P(V) * P(V)).

Markov zeigte aber, dass dies nicht der Fall ist. Die Wahrscheinlichkeit, dass ein Vokal auf einen Vokal folgt, ist nicht einfach nur die Häufigkeit von Vokalen insgesamt. Sie hängt stark davon ab, ob der vorherige Buchstabe ein Vokal oder ein Konsonant war. Das ist genau die **Markov-Eigenschaft**: Der nächste Zustand (der nächste Buchstabe) hängt nur vom aktuellen Zustand (dem vorherigen Buchstaben) ab, nicht von der gesamten Historie des Textes.

Seine Ergebnisse zeigten, dass es in der russischen Sprache (und in Sprachen im Allgemeinen) klare Muster und Abhängigkeiten bei der Abfolge von Vokalen und Konsonanten gibt. Beispielsweise ist es in vielen Sprachen wahrscheinlicher, dass auf einen Konsonanten ein Vokal folgt (KV), um Silben zu bilden, als dass zwei Konsonanten direkt aufeinanderfolgen (KK) oder zwei Vokale (VV).

Diese linguistische Analyse war nicht nur ein faszinierendes Anwendungsbeispiel, sondern diente Markov auch dazu, die mathematische Theorie der Markov-Ketten zu entwickeln und zu untermauern. Es war ein praktisches Problem, das perfekt zu der Art von stochastischen Prozessen passte, die er untersuchen wollte.

Diese frühen Arbeiten haben weitreichende Auswirkungen gehabt und bilden bis heute die Grundlage für Bereiche wie:

* **Sprachmodellierung und Spracherkennung:** moderne Systeme nutzen viel komplexere Markov-Modelle (Hidden Markov Models), um Sprache zu verarbeiten.
* **Bioinformatik:** Analyse von DNA-Sequenzen, wo die Abfolge von Nukleotiden (Basen) ebenfalls abhängige Muster aufweist.
* **Kryptographie:** Entschlüsselung von Codes.
* **Informationswissenschaft:** Verständnis der Struktur von Informationen.

Es ist faszinierend zu sehen, wie eine so "einfache" Idee, die aus der Analyse von Puschkins Gedicht entstand, zu solch weitreichenden und grundlegenden mathematischen Konzepten geführt hat!

## Frage

Er hatte bei der Analyze rausbekommen das 43% V und 57% K gab, also P(V)=0.43
und P(K)=0.57 Damit, wenn Reienfolge der VVs unabhaengig ist, wuerde P(VV) =
0.43*0.43 sein, aber eine Abzaehlung ergab P(VV) = 0.06. Bei den anderen
Kombinationen P(VK) = 0.25 P(KV) = 0.25 P(KK) = 0.19 ergaben sich P(VK) =
0.375, P(KV) =  0.375 und P(KK) = 0.19. Was sind die
Warscheinlichkeitsuebergaenge, wenn wir die Zustaende V und K haben?

## Antwort

Super! Das ist ein hervorragendes Beispiel, um die Bedeutung der Markov-Eigenschaft und die Berechnung von Übergangswahrscheinlichkeiten zu verstehen.

Sie haben ganz richtig erkannt, dass die tatsächlichen Zählungen von Markov (P(VV) = 0.06, P(VK) = 0.25, P(KV) = 0.25, P(KK) = 0.19) sich deutlich von dem unterscheiden, was man erwarten würde, wenn die Buchstabenfolgen unabhängig wären (P(V) = 0.43, P(K) = 0.57).

Genau diese Diskrepanz war der Ausgangspunkt für Markov, seine Theorie der Ketten mit Abhängigkeiten zu entwickeln.

Lassen Sie uns nun die **Übergangswahrscheinlichkeiten** berechnen. Eine Übergangswahrscheinlichkeit ist die Wahrscheinlichkeit, von einem Zustand (dem aktuellen Buchstaben) zu einem anderen Zustand (dem nächsten Buchstaben) zu gelangen. Wir bezeichnen sie als $P(\text{nächster Zustand} | \text{aktueller Zustand})$.

Wir wissen:
* $P(V) = 0.43$ (Anteil der Vokale im Text)
* $P(K) = 0.57$ (Anteil der Konsonanten im Text)

Und die *gemeinsamen Wahrscheinlichkeiten* (Anteil der Paare im Text):
* $P(VV) = 0.06$
* $P(VK) = 0.25$
* $P(KV) = 0.25$
* $P(KK) = 0.19$

Beachten Sie, dass die Summe der gemeinsamen Wahrscheinlichkeiten $0.06 + 0.25 + 0.25 + 0.19 = 0.75$ ergibt. Das liegt daran, dass diese Zahlen als **relative Häufigkeiten** der Paare im Text angegeben sind. Manchmal werden sie auch so normalisiert, dass die Summe 1 ergibt. Für die Berechnung der Übergangswahrscheinlichkeiten ist es wichtig, dass die gemeinsamen Wahrscheinlichkeiten die "Absoluthäufigkeit" der Übergänge repräsentieren, gemessen am Gesamttext.

Die Formel für eine bedingte Wahrscheinlichkeit ist $P(B|A) = \frac{P(A \text{ und } B)}{P(A)}$.

Wobei $P(A \text{ und } B)$ in unserem Fall $P(XY)$ ist (gemeinsame Wahrscheinlichkeit von X gefolgt von Y) und $P(A)$ ist $P(X)$ (die Wahrscheinlichkeit des Startbuchstabens).

**1. Wahrscheinlichkeit, dass auf V ein V folgt (P(V|V))**
* Aktueller Zustand ist Vokal (V). Die Wahrscheinlichkeit, dass ein Vokal der Start eines Paares ist, ist $P(V) = 0.43$.
* Die gemeinsame Wahrscheinlichkeit von VV ist $P(VV) = 0.06$.

    $P(V|V) = \frac{P(VV)}{P(V)} = \frac{0.06}{0.43} \approx 0.1395$
    (Das bedeutet, wenn der aktuelle Buchstabe ein Vokal ist, ist die Wahrscheinlichkeit, dass der nächste auch ein Vokal ist, etwa 13.95%)

**2. Wahrscheinlichkeit, dass auf V ein K folgt (P(K|V))**
* Aktueller Zustand ist Vokal (V). Die Wahrscheinlichkeit, dass ein Vokal der Start eines Paares ist, ist $P(V) = 0.43$.
* Die gemeinsame Wahrscheinlichkeit von VK ist $P(VK) = 0.25$.

    $P(K|V) = \frac{P(VK)}{P(V)} = \frac{0.25}{0.43} \approx 0.5814$
    (Das bedeutet, wenn der aktuelle Buchstabe ein Vokal ist, ist die Wahrscheinlichkeit, dass der nächste ein Konsonant ist, etwa 58.14%)

**Prüfung für V:** $P(V|V) + P(K|V) = 0.1395 + 0.5814 \approx 0.7209$. **Hier stimmt etwas nicht!** Die Summe der Übergangswahrscheinlichkeiten aus einem Zustand muss 1 ergeben.

Der Grund für die Diskrepanz liegt in der Interpretation der gegebenen $P(XY)$ Werte. Wenn $P(VV), P(VK), P(KV), P(KK)$ die **relativen Häufigkeiten der Übergänge im Text** sind, dann müssen wir die Berechnung leicht anpassen.

Es ist wahrscheinlicher, dass die "Abzählungen" (0.06, 0.25, 0.25, 0.19) die relativen Häufigkeiten der PAARUNG im gesamten Text widerspiegeln, nicht die bedingten Wahrscheinlichkeiten direkt.

Lassen Sie uns die Übergangswahrscheinlichkeiten basierend auf diesen Werten direkt aus den **Summen der Startzustände** berechnen:

Wenn wir von einem Vokal ausgehen, können wir entweder zu V oder zu K übergehen. Die Anzahl der Vokal-Startpaare ist die Summe der Paare, die mit V beginnen.
* Gesamte "V-startende" Paare: $P(VV) + P(VK) = 0.06 + 0.25 = 0.31$. Dieser Wert müsste eigentlich $P(V) = 0.43$ sein, wenn die Summe der Paarwahrscheinlichkeiten 1 wäre.
* Dieses Problem kommt oft vor, wenn man absolute Häufigkeiten und relative Häufigkeiten miteinander vermischt oder wenn die "Gesamtmenge" nicht klar definiert ist.

**Nehmen wir an, die gegebenen Werte 0.06, 0.25, 0.25, 0.19 sind die _Anzahlen_ der jeweiligen Übergänge oder bereits _anteilig_ an allen Übergängen, und die P(V) und P(K) sind die Gesamthäufigkeiten der einzelnen Buchstaben.**

Um die Übergangswahrscheinlichkeiten zu berechnen, müssen wir die Anzahl der Übergänge durch die Gesamtzahl der Vorkommen des *Startzustands* teilen.

**Berechnung der Übergangswahrscheinlichkeiten:**

**Ausgehend vom Zustand Vokal (V):**
Die Wahrscheinlichkeit, dass ein Vokal auf einen Vokal folgt, ist der Anteil der VV-Paare an *allen Paaren, die mit V beginnen*.
* Anzahl der Paare, die mit V beginnen: $P(VV) + P(VK) = 0.06 + 0.25 = 0.31$.
    (Hier liegt das Problem. Diese Summe müsste 0.43 sein, wenn P(V) die Summe der Startpositionen repräsentiert und die $P(XY)$ die absoluten Häufigkeiten sind. Es scheint, als ob die $P(XY)$ hier **nicht** als die üblichen $P(A \cap B)$ interpretiert werden können, wo A der erste Buchstabe ist und B der zweite, und $P(A)$ die Randwahrscheinlichkeit ist.)

**Alternative Interpretation der gegebenen Zahlen (die in der Regel zutreffend ist, wenn man Markov-Ketten betrachtet):**

* $P(V)$ und $P(K)$ sind die **stationären Verteilungen** oder die **Gesamthäufigkeiten** der Buchstaben im Text.
* $P(VV), P(VK), P(KV), P(KK)$ sind die **gemeinsamen Wahrscheinlichkeiten** der Paare, d.h., $P(erster\_Buchstabe, zweiter\_Buchstabe)$. Die Summe dieser vier Wahrscheinlichkeiten sollte 1 ergeben, wenn sie alle möglichen Paare abdecken und die gesamte Datenmenge repräsentieren. In Ihrem Fall ist $0.06 + 0.25 + 0.25 + 0.19 = 0.75$, was darauf hindeutet, dass dies entweder eine unvollständige Auflistung ist oder die Zahlen nicht perfekt eine geschlossene Verteilung bilden.

**Nehmen wir an, die gemeinsamen Wahrscheinlichkeiten sind korrekt und repräsentieren die Häufigkeit der Paare im gesamten Text.**

Dann berechnen wir die bedingten Wahrscheinlichkeiten wie folgt:

1.  **Übergang von Vokal (V):**
    * $P(V \to V) = P(V|V) = \frac{P(VV)}{P(V)}$
    * $P(V \to K) = P(K|V) = \frac{P(VK)}{P(V)}$

    Um dies zu tun, benötigen wir die **tatsächliche Häufigkeit, dass ein Vokal der Start eines Paares ist**, basierend auf den gegebenen Paaren.
    * Die Gesamtzahl der Vorkommen von Vokalen als Startbuchstabe in einem Paar ist proportional zu $P(VV) + P(VK) = 0.06 + 0.25 = 0.31$.
    * Die Gesamtzahl der Vorkommen von Konsonanten als Startbuchstabe in einem Paar ist proportional zu $P(KV) + P(KK) = 0.25 + 0.19 = 0.44$.
    * Die Summe dieser ist $0.31 + 0.44 = 0.75$.

    **Wichtig:** Dies bedeutet, dass die initialen $P(V)=0.43$ und $P(K)=0.57$ nicht direkt aus der Summe der ersten Elemente der Paare resultieren, wenn die Summe der $P(XY)$ nicht 1 ist.

    **Lassen Sie uns die Berechnung so vornehmen, dass die Summe der Übergangswahrscheinlichkeiten aus jedem Zustand 1 ergibt.**

    **1. Übergänge ausgehend von Vokal (V):**
    Wenn wir uns in einem Vokal-Zustand befinden, können wir entweder zu V oder zu K übergehen. Die Wahrscheinlichkeiten müssen sich zu 1 summieren.
    * Anzahl der VV-Übergänge: $0.06$
    * Anzahl der VK-Übergänge: $0.25$
    * Gesamtzahl der Übergänge von V: $0.06 + 0.25 = 0.31$

    * $P(V \to V) = \frac{0.06}{0.31} \approx \mathbf{0.1935}$
    * $P(V \to K) = \frac{0.25}{0.31} \approx \mathbf{0.8065}$

    Probe: $0.1935 + 0.8065 = 1.0000$ (stimmt!)

**2. Übergänge ausgehend von Konsonant (K):**
Wenn wir uns in einem Konsonanten-Zustand befinden, können wir entweder zu V oder zu K übergehen. Die Wahrscheinlichkeiten müssen sich zu 1 summieren.
* Anzahl der KV-Übergänge: $0.25$
* Anzahl der KK-Übergänge: $0.19$
* Gesamtzahl der Übergänge von K: $0.25 + 0.19 = 0.44$

    * $P(K \to V) = \frac{0.25}{0.44} \approx \mathbf{0.5682}$
    * $P(K \to K) = \frac{0.19}{0.44} \approx \mathbf{0.4318}$

    Probe: $0.5682 + 0.4318 = 1.0000$ (stimmt!)

---

**Zusammenfassend sind die Übergangswahrscheinlichkeiten (gerundet auf vier Nachkommastellen):**

* **Von Vokal (V):**
    * $P(V \to V) = 0.1935$ (Wahrscheinlichkeit, dass auf V ein V folgt)
    * $P(V \to K) = 0.8065$ (Wahrscheinlichkeit, dass auf V ein K folgt)

* **Von Konsonant (K):**
    * $P(K \to V) = 0.5682$ (Wahrscheinlichkeit, dass auf K ein V folgt)
    * $P(K \to K) = 0.4318$ (Wahrscheinlichkeit, dass auf K ein K folgt)

Diese Übergangswahrscheinlichkeiten bilden die **Übergangsmatrix** der Markov-Kette:

$$
T = \begin{pmatrix}
P(V \to V) & P(V \to K) \\
P(K \to V) & P(K \to K)
\end{pmatrix} = \begin{pmatrix}
0.1935 & 0.8065 \\
0.5682 & 0.4318
\end{pmatrix}
$$

Jede Zeile dieser Matrix summiert sich zu 1, was für Übergangsmatrizen charakteristisch ist. Diese Matrix beschreibt, wie das System (die Abfolge der Buchstaben) von einem Zustand zum nächsten übergeht, wobei der nächste Zustand nur vom aktuellen abhängt.

Man sieht hier sehr deutlich, dass die Sprache eine starke Präferenz für den Übergang von Vokal zu Konsonant und von Konsonant zu Vokal hat (um Silben zu bilden), während reine Vokal- oder Konsonantenketten weniger wahrscheinlich sind, als man bei Unabhängigkeit erwarten würde.
